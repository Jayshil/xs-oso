{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysing Onsala-1 radio spectra obtained from OSO 20m telescope\n",
    "\n",
    "In this notebook, we will analyse a spectrum of Onsala-1 molecular cloud obtained from 20m telescope at OSO. The spectra were measured in radio frequencies and have four emission lines of $CH_3CCH$. The main goal is to find the area under the lines, which is basically the integrated antenna temperature under these lines. With this we can compute the column density of the $CH_3CCH$.\n",
    "\n",
    "The focus of this notebook is Onsala-1. Once we have worked it out, we can make a routine to compute the same for the rest of the targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.io import fits\n",
    "import emcee\n",
    "import os\n",
    "from glob import glob\n",
    "import astropy.constants as con\n",
    "import utils as utl\n",
    "from scipy.optimize import minimize\n",
    "import corner\n",
    "import dynesty\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first make a list of all fits file which has spectrum of Onsala-1. We also list the system temperature and the total integration time, which we need to compute the combined/average spectrum (to gain a higher S/N)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing all of the fits file\n",
    "f1 = glob(os.getcwd() + '/Data/*.fits')\n",
    "ons, tsys, int_time = np.array([]), np.array([]), np.array([])\n",
    "print('File\\t\\tObject\\t\\tT_sys\\tINTTIME')\n",
    "print('-----------------------------------------------')\n",
    "for i in range(len(f1)):\n",
    "    hdul = fits.open(f1[i])\n",
    "    hdr = hdul[0].header\n",
    "    if hdr['OBJECT'] == 'Onsala 1':\n",
    "        ons = np.hstack((ons, f1[i]))\n",
    "        tsys, int_time = np.hstack((tsys, hdr['TSYS'])),\\\n",
    "             np.hstack((int_time, hdr['INTTIME']))\n",
    "        print(f1[i].split('/')[-1] + '\\t' + hdr['OBJECT'] + '\\t'\\\n",
    "             + str(hdr['TSYS']) + '\\t' + str(hdr['INTTIME']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now compute an average spectrum out of all of these spectra!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For zeroth spectra\n",
    "hdul5 = fits.open(ons[0])\n",
    "hdr5, dta5 = hdul5[0].header, hdul5[0].data[0][0]\n",
    "ii5 = np.arange(hdr5['NAXIS1']) + 1\n",
    "freq_all = hdr5['RESTFREQ'] + hdr5['CRVAL1'] + hdr5['CDELT1']*(ii5-hdr5['CRPIX1'])\n",
    "freq_all = int_time[0]*freq_all/tsys[0]\n",
    "temp_all = int_time[0]*dta5/tsys[0]\n",
    "# For all other spectra\n",
    "for i in range(len(ons)-1):\n",
    "    hdul5 = fits.open(ons[i+1])\n",
    "    hdr5, dta5 = hdul5[0].header, hdul5[0].data[0][0]\n",
    "    ii5 = np.arange(hdr5['NAXIS1']) + 1\n",
    "    frq5 = hdr5['RESTFREQ'] + hdr5['CRVAL1'] + hdr5['CDELT1']*(ii5-hdr5['CRPIX1'])\n",
    "    # Saving the data\n",
    "    temp_all = np.vstack((temp_all, int_time[i+1]*dta5/tsys[i+1]))\n",
    "    freq_all = np.vstack((freq_all, int_time[i+1]*frq5/tsys[i+1]))\n",
    "# Weighted average (weighted with int_time/Tsys) over all the spectra\n",
    "freq_avg = np.sum(freq_all, axis=0)/np.sum(int_time/tsys)\n",
    "temp_avg = np.sum(temp_all, axis=0)/np.sum(int_time/tsys)\n",
    "\n",
    "# Plotting the result:\n",
    "plt.figure(figsize=(16/1.5, 9/1.5))\n",
    "plt.errorbar(freq_avg/1e9, temp_avg, fmt='.', c='orangered')\n",
    "plt.axvline(hdr5['RESTFREQ']/1e9, color='b', lw=1.5, zorder=5)\n",
    "plt.axvline(hdr5['OBSFREQ']/1e9, color='k', lw=1.5, zorder=5)\n",
    "plt.xlabel('Frequency (in GHz)')\n",
    "plt.ylabel('Temperature (K)')\n",
    "plt.xlim([np.min(freq_avg/1e9), np.max(freq_avg/1e9)])\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There we go! This is a nice spectrum of Onsala 1!\n",
    "We can first convert frequency to the velocity first -- to do this we can use the following Doppler formula:\n",
    "\n",
    "$$v = c \\cdot \\frac{f_s - f_o}{f_s}$$\n",
    "\n",
    "The symbols have their usual meanings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To find the rest frame frequency\n",
    "diff = freq_avg - hdr5['OBSFREQ']\n",
    "rest_freq = hdr5['RESTFREQ']#freq_avg + diff\n",
    "# To find the velocity of the target!\n",
    "velo_avg = con.c.value*(rest_freq - freq_avg)/rest_freq\n",
    "velo_avg = velo_avg + hdr5['VLSR']# + hdr5['VELO-GEO'] + hdr5['VELO-HEL']\n",
    "# We can plot the results\n",
    "plt.figure(figsize=(16/1.5, 9/1.5))\n",
    "plt.errorbar(velo_avg/1e3, temp_avg, fmt='.', c='orangered')\n",
    "plt.xlabel('Velocity (in km/s)')\n",
    "plt.ylabel('Temperature (in K)')\n",
    "plt.xlim([np.min(velo_avg/1e3), np.max(velo_avg/1e3)])\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can plot the results\n",
    "## Binned data\n",
    "velo_bin, temp_bin, _, _ = utl.lcbin(velo_avg, temp_avg, binwidth=250)\n",
    "plt.figure(figsize=(16/1.5, 9/1.5))\n",
    "plt.errorbar(velo_avg/1e3, temp_avg, fmt='.', c='orangered', alpha=0.1)\n",
    "plt.errorbar(velo_bin/1e3, temp_bin, fmt='o', mfc='white', c='black')\n",
    "plt.xlabel('Velocity (in km/s)')\n",
    "plt.ylabel('Temperature (in K)')\n",
    "plt.xlim([0, 90])\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, there are four lines (though we cannot see them individually) along with some offset trend. What we can do is to build a model that has four gaussian models and a linear model. Then we can use `emcee` to fit the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(x, m, c, am1, am2, am3, am4, mu1, mu2, mu3, mu4, si1, si2, si3, si4):\n",
    "    ln1 = utl.line(x, m, c)\n",
    "    gau1 = utl.gaus(x, am1, mu1, si1)\n",
    "    gau2 = utl.gaus(x, am2, mu2, si2)\n",
    "    gau3 = utl.gaus(x, am3, mu3, si3)\n",
    "    gau4 = utl.gaus(x, am4, mu4, si4)\n",
    "    return ln1 + gau1 + gau2 + gau3 + gau4\n",
    "\n",
    "def chi_sqrd(x):\n",
    "    global velo_avg, temp_avg\n",
    "    m, c, am1, am2, am3, am4, mu1, mu2, mu3, mu4, si1, si2, si3, si4 = x\n",
    "    mod = model(velo_avg, m, c, am1, am2, am3, am4, mu1, mu2, mu3, mu4, si1, si2, si3, si4)\n",
    "    chi2 = (temp_avg - mod)**2\n",
    "    return np.sum(chi2)/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use `scipy.optimize.minimize` to find the \"first\" best-fitted parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xinit = np.array([0., 0.1, 0.4, 0.3, 0.13, 0.1,\\\n",
    "     11000, 18000, 35000, 62000, 1.5*1000, 1.5*1000, 1.5*1000, 1.5*1000])\n",
    "soln = minimize(chi_sqrd, x0=xinit, method='BFGS')\n",
    "\n",
    "vall = np.linspace(np.min(velo_avg), np.max(velo_avg), 10000)\n",
    "best_fit = model(vall, *soln.x)\n",
    "\n",
    "velo_bin, temp_bin, _, _ = utl.lcbin(velo_avg, temp_avg, binwidth=500)\n",
    "plt.figure(figsize=(16/1.5, 9/1.5))\n",
    "plt.errorbar(velo_avg/1e3, temp_avg, fmt='.', c='orangered', alpha=0.1)\n",
    "plt.errorbar(velo_bin/1e3, temp_bin, fmt='o', mfc='white', c='black', alpha=0.7)\n",
    "plt.plot(vall/1e3, best_fit, c='darkgreen', lw=3)\n",
    "plt.xlabel('Velocity (in km/s)')\n",
    "plt.ylabel('Temperature (in K)')\n",
    "plt.xlim([0, 90])\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the results:\n",
    "print(soln.x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `dynesty` to perform a more robust analysis!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loglike(x):\n",
    "    return -1*chi_sqrd(x)\n",
    "\n",
    "def uniform(t, a, b):\n",
    "    return (b-a)*t + a\n",
    "\n",
    "def prior_transform(ux):\n",
    "    um, uc, uam1, uam2, uam3, uam4,\\\n",
    "         umu1, umu2, umu3, umu4,\\\n",
    "         usi1, usi2, usi3, usi4 = ux\n",
    "    # Linear function:\n",
    "    m, c = uniform(um, -0.1, 0.1), stats.loguniform.ppf(uc, 1e-2, 5e-1)\n",
    "    # Amplitudes:\n",
    "    am1, am2, am3, am4 = stats.loguniform.ppf(uam1, 1e-2, 1.), stats.loguniform.ppf(uam2, 1e-2, 1.),\\\n",
    "         stats.loguniform.ppf(uam3, 1e-2, 1.), stats.loguniform.ppf(uam4, 1e-2, 1.)\n",
    "    # Central positions:\n",
    "    mu1, mu2, mu3, mu4 = stats.norm.ppf(umu1, soln.x[6], 5e3), stats.norm.ppf(umu2, soln.x[7], 5e3),\\\n",
    "         stats.norm.ppf(umu3, soln.x[8], 5e3), stats.norm.ppf(umu4, soln.x[9], 5e3)\n",
    "    # Widths:\n",
    "    si1, si2, si3, si4 = uniform(usi1, 1e3, 1e4), uniform(usi2, 1e3, 1e4),\\\n",
    "         uniform(usi3, 1e3, 1e4), uniform(usi4, 1e3, 1e4)\n",
    "    return m, c, am1, am2, am3, am4, mu1, mu2, mu3, mu4, si1, si2, si3, si4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsampler = dynesty.DynamicNestedSampler(loglike, prior_transform, ndim=14,\\\n",
    "    bound='multi', sample='rwalk')\n",
    "dsampler.run_nested()\n",
    "dres = dsampler.results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8a116efe97cecb71d500e659e06ef5c8b27a2e41c6ffe630e19c5aa9699e861e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
